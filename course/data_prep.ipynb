{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac80e694-521e-4b50-a169-c4aae8ce8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "# Data chunking\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "# Search\n",
    "from minsearch import Index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037371b-db4b-4cd9-a782-3922cc245b2b",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd780dd-258b-4760-ba8a-4f3a195f4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com'\n",
    "    postfix = 'zip/refs/heads/main'\n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/{postfix}'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    \n",
    "    return repository_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff4c32f-69d3-4948-9d51-39f616ba9d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ documents: 1217\n",
      "Evidently documents: 95\n",
      "PyTorch documents: 322\n"
     ]
    }
   ],
   "source": [
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "#### Project\n",
    "pytorch_docs = read_repo_data('pytorch', 'pytorch')\n",
    "####\n",
    "\n",
    "print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")\n",
    "print(f\"PyTorch documents: {len(pytorch_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65ad21-709b-4d59-a257-7862601cd6a7",
   "metadata": {},
   "source": [
    "### Data Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf699f-2c74-46b4-b9d3-09fc335e4e08",
   "metadata": {},
   "source": [
    "#### Simple chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade77b78-d127-4343-a1c7-17731db739d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    \"\"\"\n",
    "    The following method creates a sliding window chunk based on a given sequence, based on size + step.\n",
    "        \n",
    "    :param str: Markdown text as a string\n",
    "    :param size: the size of a batch in that seq\n",
    "    :param step: a step, where if step = size, there's 0 overlap, and if step < size, there will be an overlap of \"step\"\n",
    "    \n",
    "    :return: List of chunks as strings\n",
    "    \"\"\"\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5a0a4d-347d-4783-bdf0-e292509e8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    evidently_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b58abf-f2f5-482e-ab4d-6e82279289fb",
   "metadata": {},
   "source": [
    "#### Sections based chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d19e715-b0ef-4b70-8845-cf59327f3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_markdown_by_level(text, level=2):\n",
    "#     \"\"\"\n",
    "#     Split markdown text by a specific header level.\n",
    "    \n",
    "#     :param text: Markdown text as a string\n",
    "#     :param level: Header level to split on\n",
    "#     :return: List of sections as strings\n",
    "#     \"\"\"\n",
    "#     # This regex matches markdown headers\n",
    "#     # For level 2, it matches lines starting with \"## \"\n",
    "#     header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "#     pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "#     # Split and keep the headers\n",
    "#     parts = pattern.split(text)\n",
    "    \n",
    "#     sections = []\n",
    "#     for i in range(1, len(parts), 3):\n",
    "#         # We step by 3 because regex.split() with\n",
    "#         # capturing groups returns:\n",
    "#         # [before_match, group1, group2, after_match, ...]\n",
    "#         # here group1 is \"## \", group2 is the header text\n",
    "#         header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "#         header = header.strip()\n",
    "\n",
    "#         # Get the content after this header\n",
    "#         content = \"\"\n",
    "#         if i+2 < len(parts):\n",
    "#             content = parts[i+2].strip()\n",
    "\n",
    "#         if content:\n",
    "#             section = f'{header}\\n\\n{content}'\n",
    "#         else:\n",
    "#             section = header\n",
    "#         sections.append(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25eeffca-15fe-43c9-abcb-37a775b9e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidently_chunks = []\n",
    "\n",
    "# for doc in evidently_docs:\n",
    "#     doc_copy = doc.copy()\n",
    "#     doc_content = doc_copy.pop('content')\n",
    "#     print(doc_content)\n",
    "#     if doc_content:\n",
    "#         sections = split_markdown_by_level(doc_content, level=2)\n",
    "#         print(sections)\n",
    "#         for section in sections:\n",
    "#             section_doc = doc_copy.copy()\n",
    "#             section_doc['section'] = section\n",
    "#             evidently_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176499ce-08de-4fdc-bd51-fc8ee5fa9e7e",
   "metadata": {},
   "source": [
    "#### LLM based chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85927692-7331-478d-82ea-7783d39ecd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def llm(prompt, model=model):\n",
    "    \n",
    "#     openai_client = OpenAI()\n",
    "#     model = 'gpt-5-nano'\n",
    "\n",
    "#     messages = [\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ]\n",
    "\n",
    "#     response = openai_client.responses.create(\n",
    "#         model=model,\n",
    "#         input=messages\n",
    "#     )\n",
    "\n",
    "#     return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d677eb84-a84c-4118-801b-df15041fed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "# Split the provided document into logical sections\n",
    "# that make sense for a Q&A system.\n",
    "\n",
    "# Each section should be self-contained and cover\n",
    "# a specific topic or concept.\n",
    "\n",
    "# <DOCUMENT>\n",
    "# {document}\n",
    "# </DOCUMENT>\n",
    "\n",
    "# Use this format:\n",
    "\n",
    "# ## Section Name\n",
    "\n",
    "# Section content with all relevant details\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## Another Section Name\n",
    "\n",
    "# Another section content\n",
    "\n",
    "# ---\n",
    "# \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c68d687-0673-4858-8bd1-8f87a94c7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intelligent_chunking(text):\n",
    "#     prompt = prompt_template.format(document=text)\n",
    "#     response = llm(prompt)\n",
    "#     sections = response.split('---')\n",
    "#     sections = [s.strip() for s in sections if s.strip()]\n",
    "#     return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "908cdcc7-51e3-4653-95aa-ea417de1bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidently_chunks = []\n",
    "\n",
    "# for doc in tqdm(evidently_docs):\n",
    "#     doc_copy = doc.copy()\n",
    "#     doc_content = doc_copy.pop('content')\n",
    "\n",
    "#     sections = intelligent_chunking(doc_content)\n",
    "#     for section in sections:\n",
    "#         section_doc = doc_copy.copy()\n",
    "#         section_doc['section'] = section\n",
    "#         evidently_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89e29a-b0d1-4037-bb71-5b2146456b76",
   "metadata": {},
   "source": [
    "### Search Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2edfc-a1c1-477e-8dea-c5dd03dc2a7a",
   "metadata": {},
   "source": [
    "#### Text based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d6d38a-fa99-41c2-ab5d-874969696612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1565639d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Index(\n",
    "    text_fields=[\"chunk\", \"title\", \"description\", \"filename\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "index.fit(evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98544bbb-61ee-4621-9dcb-a007fb83f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What should be in a test dataset for AI evaluation?'\n",
    "results = index.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb6f068-2db5-4402-917b-16245c317726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x155e63610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "\n",
    "de_dtc_faq = [d for d in dtc_faq if 'data-engineering' in d['filename']]\n",
    "\n",
    "faq_index = Index(\n",
    "    text_fields=[\"question\", \"content\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "faq_index.fit(de_dtc_faq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7262f1b-adca-4782-b45a-4340bf48d8b5",
   "metadata": {},
   "source": [
    "#### vector based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af36370c-1854-45e8-b39c-f75f6b828a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee703eca-51a5-4a45-8a99-078a1592b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take from the 2nd Dataset (DE DTC FAQ) records which has a filename\n",
    "de_dtc_faq = [d for d in dtc_faq if 'data-engineering' in d['filename']]\n",
    "record = de_dtc_faq[2]\n",
    "text = record['question'] + ' ' + record['content']\n",
    "v_doc = embedding_model.encode(text)\n",
    "\n",
    "query = 'I just found out about the course. Can I enroll now?'\n",
    "v_query = embedding_model.encode(query)\n",
    "similarity = v_query.dot(v_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59d0d4b2-415a-4ec1-ad72-5e5b561ff77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa986075b8e46e884b67406a1f08174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faq_embeddings = []\n",
    "\n",
    "for d in tqdm(de_dtc_faq):\n",
    "    text = d['question'] + ' ' + d['content']\n",
    "    v = embedding_model.encode(text)\n",
    "    faq_embeddings.append(v)\n",
    "\n",
    "faq_embeddings = np.array(faq_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc29e364-5880-4a4e-a578-3448e03c265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x107e9fb60>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq_vindex = VectorSearch(keyword_fields=[])\n",
    "\n",
    "faq_vindex.fit(faq_embeddings, de_dtc_faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee5a36ac-6ebf-4ac5-81e7-5aac8da9554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Can I join the course now?'\n",
    "q = embedding_model.encode(query)\n",
    "results = faq_vindex.search(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbddd4df-fb73-4b0f-a29b-9db8e1d7f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '068529125b', 'question': 'Course - Can I follow the course after it finishes?', 'sort_order': 8, 'content': 'Yes, we will keep all the materials available, so you can follow the course at your own pace after it finishes.\\n\\nYou can also continue reviewing the homeworks and prepare for the next cohort. You can also start working on your final capstone project.', 'filename': 'faq-main/_questions/data-engineering-zoomcamp/general/008_068529125b_course-can-i-follow-the-course-after-it-finishes.md'}\n"
     ]
    }
   ],
   "source": [
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6567bf72-4a80-411b-98b0-b3d09a443def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start', 'chunk', 'title', 'description', 'filename'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidently_chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "765a1f31-1e31-4dd2-8f75-4e10d0d82493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30d6d6d227e4fd0ae393637cbb8298d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x1576c4550>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evidently\n",
    "evidently_embeddings = []\n",
    "\n",
    "for d in tqdm(evidently_chunks):\n",
    "    v = embedding_model.encode(d['chunk'])\n",
    "    evidently_embeddings.append(v)\n",
    "\n",
    "evidently_embeddings = np.array(evidently_embeddings)\n",
    "\n",
    "evidently_vindex = VectorSearch(keyword_fields=[])\n",
    "evidently_vindex.fit(evidently_embeddings, evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e5ee24a-ccb0-4f44-897c-e76c15e37fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevidently_vindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyCharmProjects/aihero/course/.venv/lib/python3.13/site-packages/minsearch/vector.py:73\u001b[39m, in \u001b[36mVectorSearch.search\u001b[39m\u001b[34m(self, query_vector, filter_dict, num_results, output_ids)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Reshape query vector for cosine similarity\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m query_vector_2d = \u001b[43mquery_vector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Compute cosine similarity\u001b[39;00m\n\u001b[32m     76\u001b[39m scores = cosine_similarity(query_vector_2d, \u001b[38;5;28mself\u001b[39m.vectors).flatten()\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "evidently_vindex.search(query, num_results=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7011c-3b7d-4779-aa82-346fae7ff5ff",
   "metadata": {},
   "source": [
    "#### Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff907a45-a31f-44b0-97e2-55d1cfca7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_index.search(query, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728a5d5-88ff-4375-86fe-33608cc33c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What are the course pre-requesites?'\n",
    "\n",
    "text_results = faq_index.search(query, num_results=5)\n",
    "\n",
    "q = embedding_model.encode(query)\n",
    "vector_results = faq_vindex.search(q, num_results=5)\n",
    "\n",
    "final_results = text_results + vector_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446b780-f761-4ebe-a115-aecfca8e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for result in final_results:\n",
    "    print(result)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e086aa-83fa-4d07-a986-c89bd39e0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_search(query):\n",
    "    return faq_index.search(query, num_results=5)\n",
    "\n",
    "def vector_search(query):\n",
    "    q = embedding_model.encode(query)\n",
    "    return faq_vindex.search(q, num_results=5)\n",
    "\n",
    "def hybrid_search(query):\n",
    "    text_results = text_search(query)\n",
    "    vector_results = vector_search(query)\n",
    "    \n",
    "    # Combine and deduplicate results\n",
    "    seen_ids = set()\n",
    "    combined_results = []\n",
    "\n",
    "    for result in text_results + vector_results:\n",
    "        if result['filename'] not in seen_ids:\n",
    "            seen_ids.add(result['filename'])\n",
    "            combined_results.append(result)\n",
    "    \n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340dca8-afcf-4fa2-b43f-5a545e89755e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
